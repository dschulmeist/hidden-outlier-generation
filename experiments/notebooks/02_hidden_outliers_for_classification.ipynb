{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Experiment 2: Hidden Outliers for Anomaly Detection\n",
    "\n",
    "This experiment demonstrates using BISECT-generated hidden outliers as a synthetic positive class for training a supervised classifier, effectively turning unsupervised anomaly detection into a supervised problem.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Unsupervised anomaly detection has a fundamental limitation: without labeled anomalies, we can't train a classifier to distinguish normal from abnormal. But what if we could **generate** realistic anomalies?\n",
    "\n",
    "**Approach**:\n",
    "1. Project data to a latent space (PCA)\n",
    "2. Generate hidden outliers using BISECT in the latent space\n",
    "3. Train a Random Forest: encoded real data = class 0, hidden outliers = class 1\n",
    "4. Use the classifier to detect real outliers\n",
    "\n",
    "## Methodology\n",
    "\n",
    "We use MNIST with one digit as \"normal\" and another as \"outlier\" (unknown at training time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from pyod.models.lof import LOF\n",
    "\n",
    "from hog_bisect import BisectHOGen\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "We simulate a realistic scenario:\n",
    "- **Training**: Only normal samples available (no outliers)\n",
    "- **Test**: Mix of normal and outlier samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "except ImportError:\n",
    "    from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Flatten and normalize\n",
    "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "# Configuration\n",
    "NORMAL_DIGIT = 1\n",
    "OUTLIER_DIGIT = 7\n",
    "N_TRAIN = 1000     # Normal samples for training\n",
    "N_TEST_NORMAL = 500\n",
    "N_TEST_OUTLIER = 50  # 10% contamination in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set: only normal samples\n",
    "X_train = x_train[y_train == NORMAL_DIGIT][:N_TRAIN]\n",
    "\n",
    "# Test set: mix of normal and outliers\n",
    "X_test_normal = x_test[y_test == NORMAL_DIGIT][:N_TEST_NORMAL]\n",
    "X_test_outlier = x_test[y_test == OUTLIER_DIGIT][:N_TEST_OUTLIER]\n",
    "X_test = np.vstack([X_test_normal, X_test_outlier])\n",
    "y_test_labels = np.array([0] * N_TEST_NORMAL + [1] * N_TEST_OUTLIER)\n",
    "\n",
    "print(f\"Training set: {X_train.shape} (all normal)\")\n",
    "print(f\"Test set: {X_test.shape} ({N_TEST_NORMAL} normal + {N_TEST_OUTLIER} outliers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-header",
   "metadata": {},
   "source": [
    "## 2. Baseline: Unsupervised LOF\n",
    "\n",
    "First, let's establish baseline performance using standard LOF (unsupervised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline-lof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF on full space\n",
    "lof_full = LOF(n_neighbors=20, contamination=0.1)\n",
    "lof_full.fit(X_test)\n",
    "auc_lof_full = roc_auc_score(y_test_labels, lof_full.decision_scores_)\n",
    "print(f\"LOF on full space (784 dims): AUC = {auc_lof_full:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pca-header",
   "metadata": {},
   "source": [
    "## 3. Project to Latent Space\n",
    "\n",
    "Fit PCA on training data (normal samples only) and project both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-pca",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "\n",
    "pca = PCA(n_components=LATENT_DIM, random_state=42)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_latent = pca.transform(X_train)\n",
    "X_test_latent = pca.transform(X_test)\n",
    "\n",
    "explained_var = np.sum(pca.explained_variance_ratio_) * 100\n",
    "print(f\"PCA latent dimension: {LATENT_DIM}\")\n",
    "print(f\"Variance explained: {explained_var:.1f}%\")\n",
    "print(f\"Training latent shape: {X_train_latent.shape}\")\n",
    "print(f\"Test latent shape: {X_test_latent.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lof-latent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF on latent space (baseline improvement)\n",
    "lof_latent = LOF(n_neighbors=20, contamination=0.1)\n",
    "lof_latent.fit(X_test_latent)\n",
    "auc_lof_latent = roc_auc_score(y_test_labels, lof_latent.decision_scores_)\n",
    "print(f\"LOF on latent space ({LATENT_DIM} dims): AUC = {auc_lof_latent:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bisect-header",
   "metadata": {},
   "source": [
    "## 4. Generate Hidden Outliers with BISECT\n",
    "\n",
    "Now we generate synthetic hidden outliers in the latent space using the BISECT algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-hidden-outliers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hidden outliers in latent space\n",
    "generator = BisectHOGen(\n",
    "    data=X_train_latent,\n",
    "    outlier_detection_method=LOF,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Generate same number of hidden outliers as training samples\n",
    "n_hidden = len(X_train_latent)\n",
    "hidden_outliers_latent = generator.fit_generate(\n",
    "    gen_points=n_hidden,\n",
    "    get_origin_type='weighted',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(hidden_outliers_latent)} hidden outliers in latent space\")\n",
    "generator.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-latent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 2 dimensions of latent space\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.scatter(X_train_latent[:, 0], X_train_latent[:, 1], \n",
    "           c='blue', alpha=0.3, s=20, label='Training data (normal)')\n",
    "ax.scatter(hidden_outliers_latent[:, 0], hidden_outliers_latent[:, 1], \n",
    "           c='red', alpha=0.5, s=30, marker='x', label='Generated hidden outliers')\n",
    "\n",
    "ax.set_xlabel('PC1', fontsize=12)\n",
    "ax.set_ylabel('PC2', fontsize=12)\n",
    "ax.set_title('Training Data vs Generated Hidden Outliers (Latent Space)', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/hidden_outliers_latent_space.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf-header",
   "metadata": {},
   "source": [
    "## 5. Train Random Forest Classifier\n",
    "\n",
    "Now we train a Random Forest using:\n",
    "- **Class 0**: Real training data (normal)\n",
    "- **Class 1**: Generated hidden outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-rf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for classifier\n",
    "X_clf_train = np.vstack([X_train_latent, hidden_outliers_latent])\n",
    "y_clf_train = np.array([0] * len(X_train_latent) + [1] * len(hidden_outliers_latent))\n",
    "\n",
    "print(f\"Classifier training set: {X_clf_train.shape}\")\n",
    "print(f\"Class distribution: {np.sum(y_clf_train == 0)} normal, {np.sum(y_clf_train == 1)} synthetic outliers\")\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_clf_train, y_clf_train)\n",
    "\n",
    "print(\"Random Forest trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-rf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "# Use probability of being an outlier (class 1) as anomaly score\n",
    "rf_proba = rf.predict_proba(X_test_latent)[:, 1]\n",
    "auc_rf_bisect = roc_auc_score(y_test_labels, rf_proba)\n",
    "\n",
    "print(f\"Random Forest + BISECT: AUC = {auc_rf_bisect:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "## 6. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'LOF (Full Space)': auc_lof_full,\n",
    "    'LOF (Latent Space)': auc_lof_latent,\n",
    "    'RF + BISECT': auc_rf_bisect\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for method, auc in results.items():\n",
    "    improvement = (auc - auc_lof_full) / auc_lof_full * 100\n",
    "    print(f\"{method:25} AUC = {auc:.3f} ({improvement:+.1f}% vs baseline)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "methods = list(results.keys())\n",
    "aucs = list(results.values())\n",
    "colors = ['#d62728', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "bars = ax.bar(methods, aucs, color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, aucs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.axhline(y=auc_lof_full, color='#d62728', linestyle='--', alpha=0.5, \n",
    "           label='Baseline')\n",
    "\n",
    "ax.set_ylabel('AUC-ROC', fontsize=12)\n",
    "ax.set_title(f'Anomaly Detection Performance Comparison\\nMNIST: Normal={NORMAL_DIGIT}, Outlier={OUTLIER_DIGIT}', \n",
    "             fontsize=14)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/classification_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi-config-header",
   "metadata": {},
   "source": [
    "## 7. Sensitivity Analysis: Number of Generated Outliers\n",
    "\n",
    "Does generating more hidden outliers improve performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitivity-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [0.5, 1.0, 1.5, 2.0]\n",
    "sensitivity_results = []\n",
    "\n",
    "for ratio in ratios:\n",
    "    n_generate = int(len(X_train_latent) * ratio)\n",
    "    \n",
    "    gen = BisectHOGen(data=X_train_latent, outlier_detection_method=LOF, seed=42)\n",
    "    hidden = gen.fit_generate(gen_points=n_generate, get_origin_type='weighted', n_jobs=1)\n",
    "    \n",
    "    if len(hidden) == 0:\n",
    "        print(f\"Ratio {ratio}: No hidden outliers generated, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Train RF\n",
    "    X_train_clf = np.vstack([X_train_latent, hidden])\n",
    "    y_train_clf = np.array([0] * len(X_train_latent) + [1] * len(hidden))\n",
    "    \n",
    "    rf_temp = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train_clf, y_train_clf)\n",
    "    \n",
    "    proba = rf_temp.predict_proba(X_test_latent)[:, 1]\n",
    "    auc = roc_auc_score(y_test_labels, proba)\n",
    "    \n",
    "    sensitivity_results.append({'ratio': ratio, 'n_generated': len(hidden), 'auc': auc})\n",
    "    print(f\"Ratio {ratio}x ({len(hidden):4d} outliers): AUC = {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sensitivity_results:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    ratios_plot = [r['ratio'] for r in sensitivity_results]\n",
    "    aucs_plot = [r['auc'] for r in sensitivity_results]\n",
    "    \n",
    "    ax.plot(ratios_plot, aucs_plot, 'o-', markersize=10, linewidth=2, color='#2ca02c')\n",
    "    ax.axhline(y=auc_lof_full, color='#d62728', linestyle='--', \n",
    "               label=f'LOF baseline ({auc_lof_full:.3f})')\n",
    "    \n",
    "    ax.set_xlabel('Ratio of Generated Outliers to Training Data', fontsize=12)\n",
    "    ax.set_ylabel('AUC-ROC', fontsize=12)\n",
    "    ax.set_title('Sensitivity: Number of Generated Hidden Outliers', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0.5, 1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/sensitivity_n_outliers.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This experiment demonstrates that **BISECT-generated hidden outliers can serve as effective synthetic anomalies** for training supervised classifiers.\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **RF + BISECT outperforms unsupervised LOF** on this anomaly detection task\n",
    "2. **Latent space projection helps** both unsupervised (LOF) and supervised (RF) approaches\n",
    "3. **The ratio of generated outliers matters less than expected** - even 0.5x or 1x ratio works well\n",
    "\n",
    "### Why Does This Work?\n",
    "\n",
    "- BISECT generates outliers in the \"area of disagreement\" between full-space and subspace models\n",
    "- These synthetic outliers represent points that are anomalous in ways that traditional detection might miss\n",
    "- Training a classifier with these points teaches it to recognize subtle anomaly patterns\n",
    "\n",
    "### Practical Implications:\n",
    "\n",
    "- When you have **only normal training data**, generate hidden outliers as synthetic positives\n",
    "- This converts unsupervised anomaly detection into supervised classification\n",
    "- Particularly effective for **high-dimensional data** where manifold projection is beneficial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
